{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a77de54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9879dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single layer lstm\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden=64):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        # layers\n",
    "        self.lstm = nn.LSTMCell(1, self.n_hidden)\n",
    "        self.linear = nn.Linear(self.n_hidden, 1)\n",
    "        \n",
    "    def forward(self, x, future=0):\n",
    "        outputs = []\n",
    "        \n",
    "        # hidden states and cell states\n",
    "        h_t0 = torch.zeros(x.size(0), self.n_hidden, dtype=torch.float32)\n",
    "        c_t0 = torch.zeros(x.size(0), self.n_hidden, dtype=torch.float32)\n",
    "        \n",
    "        for input_t in x.split(1, dim=1):\n",
    "            h_t1, c_t1 = self.lstm(input_t, (h_t0, c_t0))\n",
    "            output = self.linear(h_t1)\n",
    "            outputs += [output]\n",
    "            \n",
    "        for i in range(future): # if we should predict the future\n",
    "            h_t1, c_t1 = self.lstm(input_t, (h_t0, c_t0))\n",
    "            output = self.linear(h_t1)\n",
    "            outputs += [output]\n",
    "            \n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3d75b869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        ],\n",
       "        [0.11111111],\n",
       "        [0.22222224],\n",
       "        [0.33333334],\n",
       "        [0.44444448],\n",
       "        [0.5555556 ],\n",
       "        [0.6666667 ],\n",
       "        [0.7777778 ],\n",
       "        [0.8888889 ],\n",
       "        [1.        ]], dtype=float32),\n",
       " array([[0.        ],\n",
       "        [0.11111111],\n",
       "        [0.22222224],\n",
       "        [0.33333334],\n",
       "        [0.44444448],\n",
       "        [0.5555556 ],\n",
       "        [0.6666667 ],\n",
       "        [0.7777778 ],\n",
       "        [0.8888889 ],\n",
       "        [1.        ]], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = np.array([[200],[400],[600],[800],[1000],[1200],[1400],[1600],[1800],[2000]], dtype=np.float32)\n",
    "target = np.array([[80],[160],[240],[320],[400],[480.0], [560.0], [640.0], [720.0], [800.0]], dtype=np.float32)\n",
    "\n",
    "sc1 = MinMaxScaler(feature_range=(0,1))\n",
    "sc2 = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "sc1.fit(inputs)\n",
    "sc2.fit(target)\n",
    "\n",
    "inputs = sc1.transform(inputs)\n",
    "target = sc2.transform(target)\n",
    "\n",
    "train_input = torch.from_numpy(inputs)   # [7,1], [0:7]\n",
    "train_target = torch.from_numpy(target)  # [7,1], [0:7]\n",
    "test_input = torch.from_numpy(inputs)    # [3,1], [7:]\n",
    "test_target = torch.from_numpy(target)   # [3,1], [7:]\n",
    "\n",
    "inputs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a4ff7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in training: 0.28811925649642944\n",
      "Test loss: 0.28811925649642944\n",
      "Loss in training: 9.702205261419294e-07\n",
      "Test loss: 9.702205261419294e-07\n",
      "Loss in training: 9.329788781542447e-07\n",
      "Test loss: 9.329788781542447e-07\n",
      "Loss in training: 9.095459745367407e-07\n",
      "Test loss: 9.095459745367407e-07\n",
      "Loss in training: 8.943133025240968e-07\n",
      "Test loss: 8.943133025240968e-07\n",
      "Loss in training: 8.841403769110912e-07\n",
      "Test loss: 8.841403769110912e-07\n",
      "Loss in training: 8.772332193984766e-07\n",
      "Test loss: 8.772332193984766e-07\n",
      "Loss in training: 8.725072007109702e-07\n",
      "Test loss: 8.725072007109702e-07\n",
      "Loss in training: 8.691378639014147e-07\n",
      "Test loss: 8.691378639014147e-07\n",
      "Loss in training: 8.667512929605437e-07\n",
      "Test loss: 8.667512929605437e-07\n",
      "x_scaled 0.37555555555555553\n",
      "pred 349.9644660949707\n",
      "y_actual 350.40000000000003\n"
     ]
    }
   ],
   "source": [
    "model = LSTM()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.01)\n",
    "\n",
    "n_steps = 500\n",
    "\n",
    "# training loop\n",
    "for i in range(n_steps):\n",
    "    def closure():\n",
    "        optimizer.zero_grad()               # zero the gradient\n",
    "        out = model(train_input)            # forward pass\n",
    "        loss = criterion(out, train_target) # calculate the loss\n",
    "        loss.backward()                     # backward pass        \n",
    "        return loss\n",
    "    \n",
    "    optimizer.step(closure)                 # update parameters\n",
    "    \n",
    "    with torch.no_grad():                   # testing\n",
    "        future = 1\n",
    "        pred = model(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-1], test_target)\n",
    "        y = pred.detach().numpy()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Loss in training: {loss.item()}\")\n",
    "            print(f\"Test loss: {loss.item()}\")\n",
    "\n",
    "            \n",
    "def predict(x):\n",
    "    x_scaled = (x - 200) / (2000 - 200)\n",
    "    y_actual = x * 0.4\n",
    "    input_t = torch.tensor([[x_scaled]])\n",
    "    pred = model(input_t)\n",
    "    pred_val = pred.detach().numpy()\n",
    "    y_scaled = pred_val.item() * (800 - 80) + 80\n",
    "    print(\"x_scaled\", x_scaled)\n",
    "    print(\"pred\", y_scaled)\n",
    "    print(\"y_actual\", y_actual)\n",
    "    \n",
    "predict(876)\n",
    "\n",
    "\n",
    "# x_flatten = sc.inverse_transform(test_input).flatten()\n",
    "# y_flatten = sc.inverse_transform(test_target).flatten()\n",
    "# pred_flatten = sc.inverse_transform(y[:, :-1]).flatten()\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "\n",
    "\n",
    "# plt.plot(x_flatten, y_flatten, 'r')\n",
    "# plt.plot(x_flatten, pred_flatten, 'b--')\n",
    "# plt.show()\n",
    "\n",
    "# print(x_flatten)\n",
    "# print(y_flatten)\n",
    "# print(pred_flatten)\n",
    "\n",
    "# print(test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d9f7808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "PATH = 'single_lstm.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e60a9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and export the model to onnx\n",
    "\n",
    "input_names = [\"actual_input\"]\n",
    "output_names = [\"output\"]\n",
    "\n",
    "trained_model = LSTM()\n",
    "trained_model.load_state_dict(torch.load('single_lstm.pt'))\n",
    "trained_model.eval()\n",
    "dummy_input = torch.tensor([[0.1]])\n",
    "torch.onnx.export(trained_model, \n",
    "                  dummy_input, \n",
    "                  'single_lstm-new.onnx', \n",
    "                  verbose=True,\n",
    "                 input_names=input_names,\n",
    "                 output_names=output_names,\n",
    "                 export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4ef27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
